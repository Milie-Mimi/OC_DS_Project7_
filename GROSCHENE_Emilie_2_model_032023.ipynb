{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e588dcb0",
   "metadata": {},
   "source": [
    "# Projet 7: Implémentez un modèle de scoring (feature selection et choix du modèle de scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24520e58",
   "metadata": {},
   "source": [
    "## Table des matières: <a class=\"anchor\" id=\"0\"></a>\n",
    "\n",
    "1. [Import des librairies et configurations générales](#library)\n",
    "2. [Chargement des données](#load)\n",
    "3. [Sélection des données d'entrainement et de test](#train_test)\n",
    "4. [Feature selection](#feats)\n",
    "5. [Traitement des données déséquilibrées](#imbalanced)\n",
    "6. [Pipeline, optimisation et entrainement des modèles](#pipe)\n",
    "7. [Choix des scores](#scores)\n",
    "8. [Modélisations](#model)\n",
    "    1. [Modèle Baseline: Dummy classifier](#dummy)\n",
    "    2. [Régression logistique](#reglog)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b606a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import des librairies et configurations générales <a class=\"anchor\" id=\"library\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0f12ebf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# builtin\n",
    "#import os\n",
    "import time\n",
    "#from os import listdir\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Fonctions personnelles\n",
    "import fct_eda\n",
    "import fct_preprocessing\n",
    "import fct_model\n",
    "\n",
    "# Update Fonctions personnelles\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "# stats\n",
    "#from scipy.stats import chi2_contingency #Chi2\n",
    "#import pingouin as pg # Test Chi2 d'independance\n",
    "\n",
    "# models\n",
    "#from sklearn.experimental import enable_iterative_imputer\n",
    "#from sklearn.impute import IterativeImputer\n",
    "#from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "\n",
    "# Balancing data\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as pipe\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, fbeta_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "#import joblib # sauvegarde des modèles\n",
    "#from mlflow.models.signature import infer_signature\n",
    "#from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "\n",
    "#import gc\n",
    "#from contextlib import contextmanager\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "#\n",
    "#from sklearn.metrics import roc_auc_score, roc_curve\n",
    "#from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8795471c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Configuration Pandas\n",
    "pd_option_dictionary = {\n",
    "    'display.max_rows': 500,\n",
    "    'display.max_column': 200,\n",
    "    'display.width': 300,\n",
    "    'display.precision': 4,\n",
    "    'display.max_colwidth': None,\n",
    "    'display.float_format' : '{:.2f}'.format,\n",
    "}\n",
    "\n",
    "for pat, value in pd_option_dictionary.items():\n",
    "    pd.set_option(pat, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96c24f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Chargement des données <a class=\"anchor\" id=\"load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a181232b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application_train shape: (307505, 64)\n",
      "Processing application_train fait en 23.0s \n",
      "Bureau shape: (305811, 19)\n",
      "Processing bureau et bureau_balance fait en 73.0s \n"
     ]
    }
   ],
   "source": [
    "df = fct_preprocessing.preprocessing_no_NaN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede90822",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Vérification que le dataset consolidé ne contient pas de NaN\n",
    "fct_eda.shape_total_nan(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8295ca",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06555b6c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sélection des données d'entrainement et de test <a class=\"anchor\" id=\"train_test\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42078ff",
   "metadata": {
    "hidden": true
   },
   "source": [
    "En Machine Learning il ne faut jamais valider un modèle sur les données qui ont servi à son entrainement. Le modèle doit être testé sur des données qu'il n'a jamais vues. On aura ainsi une idée de sa performance future. Le dataset sera mélangé de façon aléatoire avant d'être divisé en deux parties:\n",
    "- un **train set** dont les données sont utilisées pour **entrainer le modèle**\n",
    "- un **test set** réservé uniquement à **l'évaluation du modèle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b0ebb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_feat = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f747db4e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Définition des features et de la target\n",
    "col_X = [f for f in df.columns if f not in ['TARGET']]\n",
    "X = df_feat[col_X]\n",
    "y = df_feat['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5767f5b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Liste des variables quantitatives\n",
    "num_feat = X.select_dtypes(exclude='object').columns.tolist()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb4d4c6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# OneHotEncoder sur nos variables catégorielles\n",
    "X, categ_feat = fct_eda.categories_encoder(X, nan_as_category = False)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45fe03",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Jeu d'entrainement (80%) et de validation (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    shuffle = True,\n",
    "                                                    random_state = 42)\n",
    "print(f\"Nb de lignes des données d'entrainement: {len(X_train)} \\nNb de lignes des données de validation: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee05618",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dcb00d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Feature selection <a class=\"anchor\" id=\"feats\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8494c0db",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Même si nous avons déjà enlevé quelques features quantitatives fortement corrélées entre elles et qualitatives en testant leur association avec la target via Chi2 et Kruskal Wallis, il reste encore beaucoup trop de variables pour les prendre toutes dans notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5c2061",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La sélection des caractéristiques est le processus de réduction du nombre de variables d'entrée lors de l'élaboration d'un modèle prédictif. On trouve 2 avantages principaux à réduire le nombre de variables en entrée du modèle:\n",
    "- **réduire le coût de calcul**\n",
    "- **améliorer la performance du modèle**\n",
    "\n",
    "Les méthodes basées sur les statistiques impliquent l'évaluation de la **relation entre chaque variable d'entrée et la variable cible à l'aide de statistiques**. Les variables qui ont la relation la plus forte avec la target seront conservées.\n",
    "\n",
    "Il existe 2 techniques principales de sélection des caractéristiques: **supervisée** et **non supervisée** (les caractéristiques seront sélectionnées en fonction de la target ou non).\n",
    "\n",
    "Les méthodes supervisées peuvent être classées en 3 groupes\n",
    "- **intrinsèques**: algorithmes qui effectuent une **sélection automatique** des caractéristiques pendant l'entrainement\n",
    "- **wrapper**: méthodes qui évaluent plusieurs modèles à l'aide de procédures qui **ajoutent et/ou suppriment des prédicteurs** afin de trouver la **combinaison optimale** qui **maximise la performance du modèle**.\n",
    "- **filtres**: sélectionne des sous-ensembles de caractéristiques en fonction de leur **relation avec la cible**.\n",
    "\n",
    "Nous allons dans un premier temps \n",
    "- supprimer les caractéristiques qui n'ont pas de variance c'est à dire les variables qui n'ont qu'une seule et même valeur parmis toutes les observations et n'apportent pas vraiment d'information (produit lors du OneHotEncoding)\n",
    "- faire une sélection des variables catégorielles puis numériques en nous aidant de **méthodes statistiques**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b295fd1a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### VarianceThreshold <a class=\"anchor\" id=\"Variance\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fd1d74",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nous allons ici supprimer les colonnes sans variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36ff448",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transform = VarianceThreshold(0)\n",
    "\n",
    "X_train_trans = transform.fit_transform(X_train)\n",
    "X_test_trans = transform.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c23c648",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mask = transform.get_support()\n",
    "\n",
    "feat_suppr = X_train.columns[~mask].tolist()\n",
    "\n",
    "print('Colonnes supprimées')\n",
    "feat_suppr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba883a1b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Liste des variables catégorielles actualisée\n",
    "categ_feat = [elem for elem in categ_feat if elem not in feat_suppr]\n",
    "\n",
    "# Liste des variables numériques actualisée\n",
    "num_feat = [elem for elem in num_feat if elem not in feat_suppr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2f625e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Nouveaux df\n",
    "X_train = X_train[num_feat + categ_feat]\n",
    "X_test = X_test[num_feat + categ_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e90518",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaf7637",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### SelectKBest <a class=\"anchor\" id=\"SelectKBest\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e64f15",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Caractéristiques qualitatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be93beb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nous allons sélectionner les variables catégorielles grâce à la méthode statistique du **Chi2**. Nous avons déjà supprimé lors de l'analyse exploratoire les variables catégorielles sans lien avec la target mais nous allons ici mesurer la force du lien et garder les plus pertinentes via la classe **SelectKBest**.\n",
    "\n",
    "Après avoir séparé les données en données d'entrainement et de test, nous allons transformer nos variables en numérique à l'aide du OneHotEncoder puis effectuer notre SelectKBest.\n",
    "\n",
    "La target étant déjà au format 0 et 1, il n'y a pas besoin de la transformer. Nous afficherons les scores sur un diagramme en barres afin d'avoir une idée du nombre de features à conserver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc6451",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# SelectKBest\n",
    "fs_categ = SelectKBest(score_func = chi2, k = 'all')\n",
    "fs_categ.fit(X_train[categ_feat], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb888798",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "plt.bar([i for i in range(len(fs_categ.scores_))], fs_categ.scores_, color = '#b8b8d2')\n",
    "plt.xlabel(\"Num features\", fontsize = 12)\n",
    "plt.ylabel(\"Chi2 Score\", fontsize = 12)\n",
    "plt.title('Feature importance scores', fontweight = 'bold', fontsize = 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb38687",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nous remarquons que certaines features ont bien plus de lien avec la target. Nous allons conserver les **10 plus importantes** et **évaluer** le modèle sur les **données de test**.\n",
    "\n",
    "Il existe de nombreuses techniques pour sélectionner les caractéristiques sur la base des résultats obtenus. Une bonne approche consiste à évaluer les modèles à l'aide de différentes méthodes de sélection de caractéristiques et de choisir la méthode qui donne le modèle le plus performant.\n",
    "\n",
    "Pour évaluer notre choix de features, nous utiliserons un modèle de **régression logistique** avec k = 10 caractéristiques puis avec différentes valeurs de k. La régression logistique est un bon modèle pour tester les méthodes de sélection des caractéristiques car elle peut être plus performante si les caractéristiques non pertinentes sont supprimées du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3205c1a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pipeline + entrainement avec sélection des 10 features\n",
    "fs_categ = SelectKBest(score_func = chi2, k = 10)\n",
    "model = LogisticRegression(max_iter = 500, random_state=42, class_weight = 'balanced')\n",
    "\n",
    "pipeline = Pipeline(steps=[('feat_select',fs_categ),\n",
    "                           ('log_reg', model)])\n",
    "\n",
    "pipeline.fit(X_train[categ_feat], y_train)\n",
    "\n",
    "#X_train_fs_categ_10 = pipeline.transform(X_train[categ_feat])\n",
    "#X_test_fs_categ_10 = pipeline.transform(X_test[categ_feat])\n",
    "\n",
    "# Evaluation données de test\n",
    "(biz_fs_chi2_15, beta_fs_chi2_15, rec_fs_chi2_15, prec_fs_chi2_15,\n",
    " acc_fs_chi2_15, auc_fs_chi2_15, y_pred_fs_chi2_15) = fct_model.eval_metrics(best_model = pipeline,\n",
    "                                                                             xtest = X_test[categ_feat],\n",
    "                                                                             ytest = y_test,\n",
    "                                                                             beta_value = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b4b10",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Au lieu de sélectionner arbitrairement k = 15, nous allons tenter de sélectionner le meilleur nombre de features en testant différents paramètres pour k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf201b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "fs_categ = SelectKBest(score_func = chi2, k = 'all')\n",
    "model = LogisticRegression(max_iter = 500, random_state=42, class_weight = 'balanced')\n",
    "\n",
    "pipe_fs_chi2 = Pipeline(steps=[('feat_select',fs_categ),\n",
    "                               ('log_reg', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7697fb69",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Méthode d'évaluation\n",
    "cv = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "# Optimisation du modèle\n",
    "best_model_fs_chi2, best_params_fs_chi2 = fct_model.optimize_and_train_model(pipeline_model = pipe_fs_chi2,\n",
    "                                                                             xtrain = X_train[categ_feat],\n",
    "                                                                             ytrain = y_train,\n",
    "                                                                             params = {'feat_select__k' : [4, 5, 6, 8, 10,\n",
    "                                                                                                           12, 14, 16, 20],},\n",
    "                                                                             scoring = make_scorer(fct_model.score_metier,\n",
    "                                                                                                   greater_is_better=False,),\n",
    "                                                                             cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836710e0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_params_fs_chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d2fb77",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Evaluation sur les données de test\n",
    "(biz_fs_chi2, beta_fs_chi2, rec_fs_chi2, prec_fs_chi2,\n",
    " acc_fs_chi2, auc_fs_chi2, y_pred_fs_chi2) = fct_model.eval_metrics(best_model = best_model_fs_chi2,\n",
    "                                                                    xtest = X_test[categ_feat],\n",
    "                                                                    ytest = y_test,\n",
    "                                                                    beta_value = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9664cb9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "D'après la grille de recherche, il semblerait qu'il faille garder les 10 variables catégorielles avec le meilleur score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadba3e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "col_quali_keep = best_model_fs_chi2[:-1].get_feature_names_out().tolist()\n",
    "col_quali_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6306536",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nous allons rajouter les variables métier qui sont en principe prises en compte dlors de la décision d'accorder ou non un prêt:\n",
    "- CREDIT_DURATION_RANGE\n",
    "- DEBT_RATIO_RANGE\n",
    "- INCOME_PER_PERSON_RANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f0150",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Liste des variables catégorielles actualisée\n",
    "categ_feat = col_quali_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718cf6bf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "categ_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a7dded",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Actualisation de la liste des variables catégorielles et des df\n",
    "# Nouveaux df\n",
    "X_train = X_train[num_feat + categ_feat]\n",
    "X_test = X_test[num_feat + categ_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6562f50a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26331bb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Caractéristiques numériques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a55171",
   "metadata": {
    "hidden": true
   },
   "source": [
    "De la même manière que pour les variables catégorielles, nous allons utiliser la fonction SelectKBest de Sklearn mais sur nos variables quantitatives en utilisant la méthode Anova (f_classif). Ce test statistique permet de déterminer si les moyennes de plusieurs échantillons de données sont identiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d2752e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "fs_num = SelectKBest(score_func = f_classif, k = 'all')\n",
    "model = LogisticRegression(max_iter = 500, random_state=42, class_weight = 'balanced')\n",
    "\n",
    "pipe_fs_anova = Pipeline(steps=[('feat_select',fs_num),\n",
    "                                ('log_reg', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0799c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "preprocessor = ColumnTransformer(transformers=[('num', StandardScaler(), num_feat)],\n",
    "                                 remainder='drop')\n",
    "fs_num = SelectKBest(score_func = f_classif, k = 'all')\n",
    "model = LogisticRegression(max_iter = 500, random_state=42, class_weight = 'balanced')\n",
    "\n",
    "pipe_fs_anova = Pipeline(steps=[('scaler', preprocessor),\n",
    "                                ('feat_select',fs_num),\n",
    "                                ('log_reg', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0382faa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Méthode d'évaluation\n",
    "cv = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "# Optimisation du modèle\n",
    "best_model_fs_anova, best_params_fs_anova = fct_model.optimize_and_train_model(pipeline_model = pipe_fs_anova,\n",
    "                                                                               xtrain = X_train[num_feat],\n",
    "                                                                               ytrain = y_train,\n",
    "                                                                               params = {'feat_select__k' : [5, 10, 15, 20, 20],},\n",
    "                                                                               scoring = make_scorer(fct_model.score_metier,\n",
    "                                                                                                     greater_is_better=False,),\n",
    "                                                                               cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7814cd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_params_fs_anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225386d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Evaluation sur les données de test\n",
    "(biz_fs_anova, beta_fs_anova, rec_fs_anova, prec_fs_anova,\n",
    " acc_fs_anova, auc_fs_anova, y_pred_fs_anova) = fct_model.eval_metrics(best_model = best_model_fs_anova,\n",
    "                                                                       xtest = X_test[num_feat],\n",
    "                                                                       ytest = y_test,\n",
    "                                                                       beta_value = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf261dd7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "D'après la grille de recherche, il semblerait qu'il faille garder les 20 variables numériques avec le meilleur score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae8a6cc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "col_quanti_keep = best_model_fs_anova[:-1].get_feature_names_out().tolist()\n",
    "col_quanti_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe3afec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Liste des variables catégorielles actualisée\n",
    "num_feat = col_quanti_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720248e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La variable age range étant déjà dans nos variables qualitatives, nous ne prenons pas la variable AGE. Les ratios calculés lors de la partie feature engineering étant importants au niveau du métier, nous les rajoutons dans notre modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64cbbe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_feat = ['CREDIT_DURATION',\n",
    "            'DEBT_RATIO', \n",
    "            'INCOME_PER_PERSON',\n",
    "            'FLAG_EMP_PHONE',\n",
    "            'REGION_RATING_CLIENT',\n",
    "            'REGION_RATING_CLIENT_W_CITY',\n",
    "            'REG_CITY_NOT_LIVE_CITY',\n",
    "            'REG_CITY_NOT_WORK_CITY',\n",
    "            'EXT_SOURCE_2',\n",
    "            'FLAG_DOCUMENT_3',\n",
    "            'YEARS_ID_PUBLISH',\n",
    "            'YEARS_LAST_PHONE_CHANGE',\n",
    "            'CREDIT_GOODS_PERC',\n",
    "            'BURO_CREDIT_ACTIVE_Active_SUM',\n",
    "            'PREV_NAME_CONTRACT_STATUS_Approved_MEAN',\n",
    "            'PREV_NAME_CONTRACT_STATUS_Refused_MEAN',\n",
    "            'PREV_CODE_REJECT_REASON_HC_MEAN',\n",
    "            'PREV_CODE_REJECT_REASON_SCOFR_MEAN',\n",
    "            'PREV_CODE_REJECT_REASON_XAP_MEAN',\n",
    "            'PREV_NAME_PRODUCT_TYPE_walk-in_MEAN',\n",
    "            'REFUSEDSK_ID_PREV_COUNT',\n",
    "            'REFUSEDCREDIT_GOODS_PERC_MEAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af236b92",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Actualisation de la liste des variables catégorielles et des df\n",
    "# Nouveaux df\n",
    "X_train = X_train[num_feat + categ_feat]\n",
    "X_test = X_test[num_feat + categ_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac58a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3175027c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Traitement des données déséquilibrées <a class=\"anchor\" id=\"imbalanced\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a653f1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lors de l'analyse exploratoire, nous avons remarqué que les données étaient très **déséquilibrées** entre les défaillants et non défaillants. Les non défaillants sont largement sur représentés (> 91%).\n",
    "\n",
    "La plupart des modèles de Machine Learning vont **ignorer la classe minoritaire** et donc avoir des **performances médiocres** dans cette classe alors qu'en général c'est la performance de la classe minoritaire qui est la plus importante.\n",
    "\n",
    "Une des approches pour traiter les ensembles de données déséquilibrés consiste à suréchantillonner la classe minoritaire. La méthode la plus simple est de **dupliquer les exemples de la classe minoritaire** même si aucune information n'est ajoutée au modèle.\n",
    "\n",
    "Il est également possible de **pondérer les classes** c'est à dire ajuster la fonction de coût du modèle de manière à ce qu'une mauvaise classification d'une observation de la classe minoritaire soit plus lourdement pénalisée qu'une mauvaise classification d'une observation de la classe majoritaire. Cette approcge contribue à améliorer la précision du modèle en rééquilibrant la distribution des classes. Comme aucun nouveau point de données n'est créé, la méthode doit ête utilisée conjointement avec d'autres méthodes comme le suréchantillonnage par exemple.\n",
    "\n",
    "Au lieu de cela, de nouveaux **exemples peuvent être synthétisés à partir des exemples existants**. Il s'agit d'un type d'augmentation de données pour la classe minoritaire appelé **SMOTE** pour (Synthetic Minority Oversampling Technique ou Technique de suréchantillonnage synthétique des minorités).\n",
    "\n",
    "Un **exemple aléatoire de la classe minoritaire** est choisi et les k plus proches voisins sont trouvés (avec k = 5 en général). **Un voisin est choisi au hasard** et un segment est tracé entre les 2 points.\n",
    " \n",
    "Il est recommandé d'utiliser d'abord un **sous-échantillonnage aléatoire** pour réduire le nombre d'exemples dans la classe minoritaire puis d'utiliser **SMOTE** pour suréchantillonner la classe minoritaire afin d'équilibrer la distribution des classes. C'est une approche efficace car les nouveaux exemples synthétiques de la classe minoritaire sont plausibles (proches dans l'espace des caractéristiques des exemples existants de la classe minoritaire).\n",
    "\n",
    "L'inconvénient général serait que les exemples synthétiques sont créés sans tenir compte de la classe majoritaire.\n",
    "\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e847eac",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Distribution de la target\n",
    "plt.figure(figsize=(5,3))\n",
    "sns.countplot(x = 'TARGET', data = df, palette=['powderblue', 'tomato'])\n",
    "plt.title('Distribution de la target', fontweight='bold', fontsize = 12)\n",
    "x = [0, 1]\n",
    "plt.xticks(x, ['Non Défaillant', 'Défaillant'])\n",
    "plt.xlabel('');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba68cdf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Counter(df['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6220e68",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pipeline, optimisation et entrainement des modèles <a class=\"anchor\" id=\"pipe\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e124ef5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nous allons dans un premier temps créer une **pipeline** pour chacun de nos modèles. Cette pipeline va nous permettre d'affecter des étapes de preprocessing à nos données, c'est à dire des transformations comme le **traitement des données déséquilibrées**, la **standardisation**, et de choisir le **type de modèle**.\n",
    "\n",
    "Cette pipeline sera ensuite intégrée dans une fonction d'optimisation et d'entrainement qui va utiliser la **validation croisée** pour tester la robustesse du modèle prédictif en répétant la procédure de split. Elle donnera plusieurs erreurs d'apprentissage et de test et donc une **estimation de la variabilité de la performance de généralisation du modèle**. \n",
    "\n",
    "Nous allons comparer l'erreur de validation avec l'erreur d'entrainement. On va créer un **validation set** qui va nous permettre d'optimiser les réglages du modèle qui donne les meilleures performances tout en gardant de côté les données du test set pour évaluer le modèle sur des données qu'il n'aura jamais vues.\n",
    "\n",
    "Le réglage des hyperparamètres s'effectuera soit à l'aide du  **GridSearchCV** qui va tester toutes les combinaisons possibles d'hyperparamètres afin de trouver celles qui vont minimiser le plus l'erreur (méthode exhaustive très **coûteuse en termes de puissance de calcul et de temps**), soit du **RandomizedSearchCV** qui va sélectionner des combinaisaons aléatoires d'hyperparamètres. Cette méthode est **un peu moins précise mais beaucoup plus rapide**. Elle sera utilisée pour les modèles plus complexes.\n",
    "\n",
    "Enfin, pour évaluer la **performance réelle de nos modèles**, nous calculerons les metrics choisis sur les données de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4c33fd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Choix des scores <a class=\"anchor\" id=\"scores\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef75d22",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Si l'on se réfère au fichier de description des colonnes:\n",
    "- **1** => clients a des difficultés de paiement, il a eu un retard de paiement de plus de X jours sur au moins une des Y premières échéances du prêt dans notre échantillon (**défaillant**)\n",
    "- **0** => tous les autres cas (**non défaillant**)\n",
    "\n",
    "Sur une matrice de confusion, les défaillants représentent la classe positive (Y=1) et les non défaillants la classe négative (Y=0).\n",
    "\n",
    "Comme il serait extrêment coûteux pour la banque d'accorder un crédit à un client défaillant qui ne le rembourserait pas ou en partie, il nous faut **minimiser le nombre de faux négatifs** c'est à dire un client prédit non défaillant alors qu'il est défaillant.\n",
    "\n",
    "Il faut également tâcher de **minimiser les faux positifs** c'est à dire prédire qu'un client est défaillant alors qu'il ne l'est pas (risque de perte de clients, de manque à gagner).\n",
    "\n",
    "Cependant, un faux positif n'a pas le même coût qu'un faux négatif. Ce dernier est beaucoup plus coûteux pour la banque. **Nous accorderons donc 10 fois plus de poids aux faux négatifs** et **2 fois plus de poids aux faux positifs** (fonction coût métier). Les modèles seront évalués sur ce score métier.\n",
    "\n",
    "Le **Rappel (Recall)** qui mesure le taux de vrais positifs est à favoriser au détriment de la précision qui est la capacité du classificateur à ne pas étiqueter comme positif un échantillon qui est négatif.\n",
    "\n",
    "Pour faire cela, nous allons nous baser sur le **F-beta score** qui est la moyenne harmonique pondérée de la précision et du rappel. Le paramètre bêta détermine le poids du rappel dans le score. Lorsqu'il est suppérieur à un, il favorise le rappel. Nous testerons plusieurs valeurs pour le beta et garderons celui qui donne le meilleur score.\n",
    "\n",
    "Nous mettrons également l'**accuracy** et l'**AUC** comme éléments de comparaison. Le **temps d'entrainement** sera également tracké."
   ]
  },
  {
   "attachments": {
    "Matrice.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "2550f839",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![Matrice.PNG](attachment:Matrice.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d6280c",
   "metadata": {},
   "source": [
    "## Modélisations <a class=\"anchor\" id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781dbd2e",
   "metadata": {},
   "source": [
    "Nous cherchons à classer les demandes en **crédit accordé ou refusé**. Il s'agit donc d'un modèle de **classification**.modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0462ade5",
   "metadata": {},
   "source": [
    "ne pas avoir de rouge\n",
    "\n",
    "si on max le rappel on n'a que des vp donc pas de fn => ce qu'on veut (num = denominateur)\n",
    "\n",
    "formule rappel + facteur fn à min (+10*fn + 2*fp)\n",
    "\n",
    "\n",
    "predict proba rand 0 et 1\n",
    "\n",
    "\n",
    "precision entre 0.6 et 1\n",
    "ypred proba > seuil\n",
    "boucle sur chacun des seuils (predict_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SEPARER PARTIE ENTRAINEMENT ET D'EVALUATION\n",
    "predict proba puis jouer avec le seuil => faire boucle entre 0.3 et 0.8 + courbe précision recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca89de8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Modèle Baseline: Dummy classifier <a class=\"anchor\" id=\"dummy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d074302",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ce classificateur fait des prédictions en utilisant des règles simples. Il est utile comme **base de référence simple** à comparer avec d'autres classificateurs et ne sera pas optimisé. Il ignore les variables en entrée et par conséquent, n'utilise aucune information provenant des features. Il n'y a donc **pas besoin de transformer au préalable nos features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17297bd2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dummy, dummy_params, dummy_name, dummy_duration = fct_model.best_model(model_name = 'Baseline - Dummy classifier',\n",
    "                                                                       model = DummyClassifier(random_state = 42), \n",
    "                                                                       cv = KFold(n_splits = 5,\n",
    "                                                                                  shuffle = True,\n",
    "                                                                                  random_state = 42),\n",
    "                                                                       xtrain = X_train,\n",
    "                                                                       numeric_features = num_feat,\n",
    "                                                                       numeric_transformer = StandardScaler(),\n",
    "                                                                       ytrain = y_train,\n",
    "                                                                       params = {'classifier__strategy' : ['most_frequent',\n",
    "                                                                                                           'prior',\n",
    "                                                                                                           'stratified',\n",
    "                                                                                                           'uniform'],},\n",
    "                                                                       scoring = make_scorer(fct_model.score_metier,\n",
    "                                                                                             greater_is_better=False),\n",
    "                                                                       xtest = X_test,\n",
    "                                                                       ytest = y_test,\n",
    "                                                                       oversampling_strategy = 0.1,\n",
    "                                                                       undersampling_strategy = 0.5, \n",
    "                                                                       balanced = False,\n",
    "                                                                       Randomized = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b3a2b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dummy_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa058433",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Evaluation sur les données de test\n",
    "(biz_dummy, beta_dummy, rec_dummy, prec_dummy,\n",
    " acc_dummy, auc_dummy, y_pred_dummy) = fct_model.eval_metrics(best_model = dummy,\n",
    "                                                              xtest = X_test,\n",
    "                                                              ytest = y_test,\n",
    "                                                              beta_value = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cef3d34",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fct_model.matrice_confusion(ytest = y_test,\n",
    "                            ypred = y_pred_dummy,\n",
    "                            model_name = dummy_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accb6025",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Démarche MLOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b43fa5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece5ae7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!mlflow --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af3687e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Création du tracking cad où MLFlow sauvegarde les runs\n",
    "mlflow.set_tracking_uri(\"file:///Users/milie/01_PYTHON/4. OPEN_CLASSROOMS/07_PROJET_7/mlruns\")\n",
    "\n",
    "# Création d'un experiment\n",
    "experiment_id = mlflow.create_experiment(\"Training binary classifier\")\n",
    "\n",
    "\n",
    "with mlflow.start_run(experiment_id = experiment_id):\n",
    "    start_Dummy = time.time()\n",
    "    model = DummyClassifier()\n",
    "\n",
    "    # Sélection des hyperparamètres\n",
    "    params = {'strategy' : ['most_frequent', 'prior', 'stratified', 'uniform'],}\n",
    "    scoring = make_scorer(recall_score)\n",
    "\n",
    "    best_model_Dummy, best_params_Dummy = optimize_and_train_model(pipeline_model = model,\n",
    "                                                                    xtrain = X_train,\n",
    "                                                                    ytrain = y_train,\n",
    "                                                                    params = params,\n",
    "                                                                    scoring = scoring)\n",
    "\n",
    "\n",
    "    duration_Dummy = time.time() - start_Dummy\n",
    "    \n",
    "    # Evaluation du modèle\n",
    "    (recall, precision, accuracy, auc) = eval_metrics(best_model = best_model_Dummy,\n",
    "                                                      xtest = X_test,\n",
    "                                                      ytest = y_test)\n",
    "    \n",
    "    print(f\"DummyClassifier Model with param strategy = {best_params_Dummy['strategy']}\")\n",
    "    print()\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"AUC: {auc:.2f}\")\n",
    "    print(f\"Train time: {duration_Dummy:.2f}\")\n",
    "    \n",
    "    # log des paramètres et scores à chaque fois que le modèle est lancé\n",
    "    mlflow.log_param(\"strategy\", best_params_Dummy['strategy'])\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "    mlflow.log_metric(\"Tps_entrainement\", duration_Dummy)\n",
    "    \n",
    "    mlflow.sklearn.log_model(best_model_Dummy, \"dummyclassifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70e1590",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Régression logistique <a class=\"anchor\" id=\"reglog\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b875ef1e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La régression logistique est un modèle statistique qui permet d'étudier la **relation entre une variable binaire** dite variable dépendante / cible et **une ou plusieurs variables indépendantes**.\n",
    "\n",
    "Il s'agit d'un **modèle linéaire** généralisé utilisant une fonction logistique comme fonction de lien. Il permet également de prédire la **probabilité qu'un événement arrive ou non** à partir de l'optimisation des coefficients de régression. Lorsque la valeur est > à un seuil, l'événement est susceptible de se produire alors que lorsque cette valeur est < au même seuil, il ne l'est pas.\n",
    "\n",
    "Nous allons tenter d'optimiser ce modèle en jouant sur les **features**, le traitement du **déséquilibre des classes** et les **hyperparamètres** via **cross validation** et **GridSearch**:\n",
    "- penalty: pénalité\n",
    "- solver: algorithme à utiliser pour l'optimisation\n",
    "- C : force de la pénalité (valeurs plus petites => régularisation plus forte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cbb204",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Modélisation sur données non équilibrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f43559",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reglog, reglog_params, reglog_name, reglog_duration = fct_model.best_model(model_name = 'Régression Logistique',\n",
    "                                                                           model = LogisticRegression(max_iter = 200,\n",
    "                                                                                                      random_state=42),\n",
    "                                                                           cv = KFold(n_splits = 5,\n",
    "                                                                                      shuffle = True,\n",
    "                                                                                      random_state = 42),\n",
    "                                                                           xtrain = X_train,\n",
    "                                                                           numeric_features = num_feat,\n",
    "                                                                           numeric_transformer = StandardScaler(),\n",
    "                                                                           ytrain = y_train,\n",
    "                                                                           params = {\"classifier__penalty\": ['l2', 'l1'],\n",
    "                                                                                     \"classifier__solver\": ['lbfgs', 'saga'],\n",
    "                                                                                      \"classifier__C\": [100, 10, 1.0, \n",
    "                                                                                                        0.1, 0.01],},\n",
    "                                                                           scoring = make_scorer(fct_model.score_metier, \n",
    "                                                                                                 greater_is_better=False),\n",
    "                                                                           xtest = X_test,\n",
    "                                                                           ytest = y_test,\n",
    "                                                                           oversampling_strategy = 0.1,\n",
    "                                                                           undersampling_strategy = 0.5,\n",
    "                                                                           balanced = False,\n",
    "                                                                           Randomized = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2f58e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reglog_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d1c9a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Evaluation sur les données de test\n",
    "(biz_reglog, beta_reglog, rec_reglog, prec_reglog,\n",
    " acc_reglog, auc_reglog, y_pred_reglog) = fct_model.eval_metrics(best_model = reglog,\n",
    "                                                                 xtest = X_test,\n",
    "                                                                 ytest = y_test,\n",
    "                                                                 beta_value = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543aab8a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fct_model.matrice_confusion(ytest = y_test,\n",
    "                            ypred = y_pred_reglog,\n",
    "                            model_name = reglog_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082c247a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Modélisation sur données rééquilibrées: pondération des classes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39caf43c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Chaque algorithme de classification SKlearn possède un paramètre appelé **class_weight** qui permet de gérer le déséquilibre des classes. Nous allons tester via la GridSearch avec le paramètre **'balanced'** (ajustement automatique des poids de manière inversement proportionnelle aux fréquences des classes dans les données d'entrée):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600acfa7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(reglog_cw, reglog_params_cw, \n",
    " reglog_name_cw, reglog_duration_cw) = fct_model.best_model(model_name = 'Régression Logistique',\n",
    "                                                            model = LogisticRegression(max_iter = 200,\n",
    "                                                                                       random_state=42,\n",
    "                                                                                       class_weight='balanced'),\n",
    "                                                            cv = KFold(n_splits = 5, shuffle = True, random_state = 42),\n",
    "                                                            xtrain = X_train,\n",
    "                                                            numeric_features = num_feat,\n",
    "                                                            numeric_transformer = StandardScaler(),\n",
    "                                                            ytrain = y_train,\n",
    "                                                            params = {\"classifier__penalty\": ['l2', 'l1'],\n",
    "                                                                      \"classifier__solver\": ['lbfgs', 'saga'],\n",
    "                                                                      \"classifier__C\": [100, 10, 1.0, 0.1, 0.01],},\n",
    "                                                            scoring = make_scorer(fct_model.score_metier,\n",
    "                                                                                  greater_is_better=False),\n",
    "                                                            xtest = X_test,\n",
    "                                                            ytest = y_test,\n",
    "                                                            oversampling_strategy = 0.1,\n",
    "                                                            undersampling_strategy = 0.5,\n",
    "                                                            balanced = False,\n",
    "                                                            Randomized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2065a9f5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reglog_params_cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda29d6a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Evaluation sur les données de test\n",
    "(biz_reglog_cw, beta_reglog_cw, rec_reglog_cw, prec_reglog_cw,\n",
    " acc_reglog_cw, auc_reglog_cw, y_pred_reglog_cw) = fct_model.eval_metrics(best_model = reglog_cw,\n",
    "                                                                          xtest = X_test,\n",
    "                                                                          ytest = y_test,\n",
    "                                                                          beta_value = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c188a66",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fct_model.matrice_confusion(ytest = y_test,\n",
    "                            ypred = y_pred_reglog_cw,\n",
    "                            model_name = reglog_name_cw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d8921",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Modélisation sur données rééquilibrées: sous échantillonage + SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e94765",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Avec sur-échantillonnage de la classe minoritaire (10% de la classe majoritaire ~= 23000) et sous échantillonnage pour réduire la classe majoritaire (50% de plus que la classe minoritaire ~= 46000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27841490",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(reglog_smote1050, reglog_smote_params1050,\n",
    " reglog_smote_name1050, reglog_smote_duration1050) = fct_model.best_model(model_name = 'Régression Logistique - SMOTE 10/50',\n",
    "                                                                          model = LogisticRegression(max_iter = 200, \n",
    "                                                                                                     random_state=42,),\n",
    "                                                                          cv = KFold(n_splits = 5,\n",
    "                                                                                     shuffle = True,\n",
    "                                                                                     random_state = 42),\n",
    "                                                                          xtrain = X_train,\n",
    "                                                                          numeric_features = num_feat,\n",
    "                                                                          numeric_transformer = StandardScaler(),\n",
    "                                                                          ytrain = y_train,\n",
    "                                                                          params = {\"classifier__penalty\": ['l2', 'l1'],\n",
    "                                                                                    \"classifier__solver\": ['lbfgs', 'saga'],\n",
    "                                                                                    \"classifier__C\": [100, 10, 1.0, 0.1, 0.01],},\n",
    "                                                                          scoring = make_scorer(fct_model.score_metier, \n",
    "                                                                                                greater_is_better=False),\n",
    "                                                                          xtest = X_test,\n",
    "                                                                          ytest = y_test,\n",
    "                                                                          oversampling_strategy = 0.1,\n",
    "                                                                          undersampling_strategy = 0.5,\n",
    "                                                                          balanced = True,\n",
    "                                                                          Randomized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab4236c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reglog_smote_params1050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf17f058",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Evaluation sur les données de test\n",
    "(biz_reglog_SMOTE1050, beta_reglog_SMOTE1050, rec_reglog_SMOTE1050, prec_reglog_SMOTE1050,\n",
    " acc_reglog_SMOTE1050, auc_reglog_SMOTE1050, y_pred_reglog_SMOTE1050) = fct_model.eval_metrics(best_model = reglog_smote1050,\n",
    "                                                                                               xtest = X_test,\n",
    "                                                                                               ytest = y_test,\n",
    "                                                                                               beta_value = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3178259a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fct_model.matrice_confusion(ytest = y_test,\n",
    "                            ypred = y_pred_reglog_SMOTE1050,\n",
    "                            model_name = reglog_smote_name1050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be629861",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Avec sur-échantillonnage de la classe minoritaire (20% de la classe majoritaire) et sous échantillonnage pour réduire la classe majoritaire (30% de plus que la classe minoritaire):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c8d53",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(reglog_smote2030, reglog_smote_params2030,\n",
    " reglog_smote_name2030, reglog_smote_duration2030) = fct_model.best_model(model_name = 'Régression Logistique - SMOTE 20/30',\n",
    "                                                                          model = LogisticRegression(max_iter = 200, \n",
    "                                                                                                     random_state=42,),\n",
    "                                                                          cv = KFold(n_splits = 5,\n",
    "                                                                                     shuffle = True,\n",
    "                                                                                     random_state = 42),\n",
    "                                                                          xtrain = X_train,\n",
    "                                                                          numeric_features = num_feat,\n",
    "                                                                          numeric_transformer = StandardScaler(),\n",
    "                                                                          ytrain = y_train,\n",
    "                                                                          params = {\"classifier__penalty\": ['l2', 'l1'],\n",
    "                                                                                    \"classifier__solver\": ['lbfgs', 'saga'],\n",
    "                                                                                    \"classifier__C\": [100, 10, 1.0, 0.1, 0.01],},\n",
    "                                                                          scoring = make_scorer(fct_model.score_metier,\n",
    "                                                                                                greater_is_better=False),\n",
    "                                                                          xtest = X_test,\n",
    "                                                                          ytest = y_test,\n",
    "                                                                          oversampling_strategy = 0.2,\n",
    "                                                                          undersampling_strategy = 0.3,\n",
    "                                                                          balanced = True,\n",
    "                                                                          Randomized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e637bc79",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reglog_smote_params2030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b02c7a0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Evaluation sur les données de test\n",
    "(biz_reglog_SMOTE2030, beta_reglog_SMOTE2030, rec_reglog_SMOTE2030, prec_reglog_SMOTE2030,\n",
    " acc_reglog_SMOTE2030, auc_reglog_SMOTE2030, y_pred_reglog_SMOTE2030) = fct_model.eval_metrics(best_model = reglog_smote2030,\n",
    "                                                                                               xtest = X_test,\n",
    "                                                                                               ytest = y_test,\n",
    "                                                                                               beta_value = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e14fbb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fct_model.matrice_confusion(ytest = y_test,\n",
    "                            ypred = y_pred_reglog_SMOTE2030,\n",
    "                            model_name = reglog_smote_name2030)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1318213d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Avec sur-échantillonnage de la classe minoritaire (10% de la classe majoritaire) et sous échantillonnage pour réduire la classe majoritaire (60% de plus que la classe minoritaire):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1efc6eb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(reglog_smote1060, reglog_smote_params1060,\n",
    " reglog_smote_name1060, reglog_smote_duration1060) = fct_model.best_model(model_name = 'Régression Logistique - SMOTE 10/60',\n",
    "                                                                          model = LogisticRegression(max_iter = 200, \n",
    "                                                                                                     random_state=42,),\n",
    "                                                                          cv = KFold(n_splits = 5,\n",
    "                                                                                     shuffle = True,\n",
    "                                                                                     random_state = 42),\n",
    "                                                                          xtrain = X_train,\n",
    "                                                                          numeric_features = num_feat,\n",
    "                                                                          numeric_transformer = StandardScaler(),\n",
    "                                                                          ytrain = y_train,\n",
    "                                                                          params = {\"classifier__penalty\": ['l2', 'l1'],\n",
    "                                                                                    \"classifier__solver\": ['lbfgs', 'saga'],\n",
    "                                                                                    \"classifier__C\": [100, 10, 1.0, 0.1, 0.01],},\n",
    "                                                                          scoring = make_scorer(fct_model.score_metier, \n",
    "                                                                                                greater_is_better=False),\n",
    "                                                                          xtest = X_test,\n",
    "                                                                          ytest = y_test,\n",
    "                                                                          oversampling_strategy = 0.1,\n",
    "                                                                          undersampling_strategy = 0.6,\n",
    "                                                                          balanced = True,\n",
    "                                                                          Randomized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693cecd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reglog_smote_params1060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f6c14",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Evaluation sur les données de test\n",
    "(biz_reglog_SMOTE1060, beta_reglog_SMOTE1060, rec_reglog_SMOTE1060, prec_reglog_SMOTE1060,\n",
    " acc_reglog_SMOTE1060, auc_reglog_SMOTE1060, y_pred_reglog_SMOTE1060) = fct_model.eval_metrics(best_model = reglog_smote1060,\n",
    "                                                                                               xtest = X_test,\n",
    "                                                                                               ytest = y_test,\n",
    "                                                                                               beta_value = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f73ca76",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fct_model.matrice_confusion(ytest = y_test,\n",
    "                            ypred = y_pred_reglog_SMOTE1060,\n",
    "                            model_name = reglog_smote_name1060)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701af998",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Le choix du traitement du déséquilibre des classes par class weight balanced donnant les meilleurs résultats, nous partirons de cette méthode pour le prochain modèle: le LightGBM. Si nous avions choisi la méthode SMOTE, nous aurions vérifier la distribution de nos variables avant et après."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160691f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p>POURQUOI?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d77d223",
   "metadata": {},
   "source": [
    "### LightGBM <a class=\"anchor\" id=\"lightgbm\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa4dc4",
   "metadata": {},
   "source": [
    "Basé sur des algorithmes **d’arbre de décision**, LightGBM (Light Gradient Boosting Machine) est utilisé pour le classement, la classification et de nombreuses autres tâches de Machine Learning. C'est un algorithme développé par Microsoft et publié en 2016 qui est basé sur le **renforcement de gradient** (Gradient Boosting). \n",
    "\n",
    "L'objectif est de former plusieurs modèles utilisant le même algorithme d'apprentissage. Une **combinaison de modèles individuels simples** crée un **modèle plus fort et puissant**.\n",
    "\n",
    "- Création d'un **modèle simple** qui est entrainé sur les données.\n",
    "- Un **second modèle** est construit pour tenter de **corriger les erreurs** présentes dans le premier modèle. Les erreurs sont minimisées par l’algorithme de descente de gradient. Chaque arbre ajouté va compenser les erreurs commises précédemment **sans détériorer les prédictions qui ont été justes**. La base d'apprentissage estdifférente.\n",
    "- Cette procédure se poursuit et des modèles sont ajoutés jusqu’à ce que l’ensemble complet des données de formation soit prédit correctement ou que le nombre maximal de modèles soit ajouté.\n",
    "- Les prédictions du dernier modèle ajouté seront les prédictions globales fournies par les anciens modèles d’arbres.\n",
    "\n",
    "https://blent.ai/blog/a/lightgbm-mieux-que-xgboost\n",
    "\n",
    "Cet algorithme offre de très bonnes performances et nous permettra d'analyser l'importance des variables globales.\n",
    "\n",
    "Lors de l'optimisation des hyperparamètres, nous tenterons un approche par GridSearchCV sur les hyperparamètres suivants:\n",
    "- **n_estimators** = nombre d'arbres de décision (il est préférable d'en avoir plusieurs)\n",
    "- **max_depth** = profondeur de chaque arbre qui contrôle le degré de spécialisation de chaque arbre par rapport à l'ensemble des données d'apprentissage (viser une profondeur modeste). Il existe deux façons principales de **contrôler la complexité des arbres** : la **profondeur maximale** des arbres et le **nombre maximal des feuilles** dans l'arbre.\n",
    "- **learning_rate**: importance de la contribution de chaque modèle à la prédiction de l'ensemble (taux plus faibles => plus d'arbres de décision)\n",
    "\n",
    "https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html\n",
    "\n",
    "https://machinelearningmastery.com/light-gradient-boosted-machine-lightgbm-ensemble/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989973d9",
   "metadata": {},
   "source": [
    "#### Modélisation sur données rééquilibrées par class weight + hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"classifier__ num_iterations\": [10, 50, 100, 500, 1000, 5000],\n",
    "          \"classifier__ max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "          \"classifier__ num_leaves\": [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n",
    "          \"classifier__ learning_rate\": [0.0001, 0.001, 0.01, 0.1, 1.0],}\n",
    "\n",
    "lgb, lgb_params, lgb_name, lgb_duration = fct_model.best_model(model_name = 'LightGBM',\n",
    "                                                               model = LGBMClassifier(random_state = 42,\n",
    "                                                                                      class_weight='balanced'),\n",
    "                                                               cv = KFold(n_splits = 5, \n",
    "                                                                          shuffle = True, \n",
    "                                                                          random_state = 42),\n",
    "                                                               xtrain = X_train,\n",
    "                                                               numeric_features = num_feat,\n",
    "                                                               numeric_transformer = StandardScaler(),\n",
    "                                                               ytrain = y_train,\n",
    "                                                               params = params,\n",
    "                                                               scoring = make_scorer(fct_model.score_metier,\n",
    "                                                                                     greater_is_better=False),\n",
    "                                                               xtest = X_test,\n",
    "                                                               ytest = y_test,\n",
    "                                                               oversampling_strategy = 0.1,\n",
    "                                                               undersampling_strategy = 0.5,\n",
    "                                                               balanced = False,\n",
    "                                                               Randomized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece27190",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf930a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation sur les données de test\n",
    "(biz_lgb, beta_lgb, rec_lgb, prec_lgb,\n",
    " acc_lgb, auc_lgb, y_pred_lgb) = fct_model.eval_metrics(best_model = lgb,\n",
    "                                                        xtest = X_test,\n",
    "                                                        ytest = y_test,\n",
    "                                                        beta_value = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e50b58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fct_model.matrice_confusion(ytest = y_test,\n",
    "                            ypred = y_pred_lgb,\n",
    "                            model_name = lgb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a90b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"classifier__ num_iterations\": [10, 50, 100, 500, 1000, 5000],\n",
    "          \"classifier__ max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "          \"classifier__ num_leaves\": [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n",
    "          \"classifier__ learning_rate\": [0.0001, 0.001, 0.01, 0.1, 1.0],}\n",
    "\n",
    "lgb, lgb_params, lgb_name, lgb_duration = fct_model.best_model(model_name = 'LightGBM',\n",
    "                                                               model = LGBMClassifier(random_state = 42,\n",
    "                                                                                      class_weight='balanced'),\n",
    "                                                               cv = KFold(n_splits = 5, \n",
    "                                                                          shuffle = True, \n",
    "                                                                          random_state = 42),\n",
    "                                                               xtrain = X_train,\n",
    "                                                               numeric_features = num_feat,\n",
    "                                                               numeric_transformer = StandardScaler(),\n",
    "                                                               ytrain = y_train,\n",
    "                                                               params = params,\n",
    "                                                               scoring = make_scorer(fbeta_score, beta=100),\n",
    "                                                               xtest = X_test,\n",
    "                                                               ytest = y_test,\n",
    "                                                               oversampling_strategy = 0.1,\n",
    "                                                               undersampling_strategy = 0.5,\n",
    "                                                               balanced = False,\n",
    "                                                               Randomized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c2143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4387131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation sur les données de test\n",
    "(biz_lgb, beta_lgb, rec_lgb, prec_lgb,\n",
    " acc_lgb, auc_lgb, y_pred_lgb) = fct_model.eval_metrics(best_model = lgb,\n",
    "                                                        xtest = X_test,\n",
    "                                                        ytest = y_test,\n",
    "                                                        beta_value = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d3f5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fct_model.matrice_confusion(ytest = y_test,\n",
    "                            ypred = y_pred_lgb,\n",
    "                            model_name = lgb_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113920bd",
   "metadata": {},
   "source": [
    "#### Choix du beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edff9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(1,200,10):\n",
    "    y_pred = lgb.predict(X_test)\n",
    "    score = fbeta_score(y_true = y_test,\n",
    "                        y_pred = y_pred,\n",
    "                        beta = b)\n",
    "    print(f'Score avec beta = {b}: {round(score,4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13785c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"classifier__ num_iterations\": [10, 50, 100, 500, 1000, 5000],\n",
    "                                              \"classifier__ max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                                              \"classifier__ num_leaves\": [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n",
    "                                              \"classifier__ learning_rate\": [0.0001, 0.001, 0.01, 0.1, 1.0],},\n",
    "\n",
    "\n",
    "lgba, lgba_params, lgba_name, lgba_duration = fct_model.best_model(model_name = 'LightGBM',\n",
    "                                                               model = LGBMClassifier(random_state = 42,\n",
    "                                                                                      class_weight='balanced'),\n",
    "                                                               cv = KFold(n_splits = 5, \n",
    "                                                                          shuffle = True, \n",
    "                                                                          random_state = 42),\n",
    "                                                               xtrain = X_train,\n",
    "                                                               numeric_features = num_feat,\n",
    "                                                               numeric_transformer = StandardScaler(),\n",
    "                                                               ytrain = y_train,\n",
    "                                                               params = params,\n",
    "                                                               scoring = make_scorer(fbeta_score, beta=100),\n",
    "                                                               xtest = X_test,\n",
    "                                                               ytest = y_test,\n",
    "                                                               oversampling_strategy = 0.1,\n",
    "                                                               undersampling_strategy = 0.5,\n",
    "                                                               balanced = False,\n",
    "                                                               Randomized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24153bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgba_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fct_model.eval_metrics(best_model = lgba,\n",
    "                                                        xtest = X_test,\n",
    "                                                        ytest = y_test,\n",
    "                                                        beta_value = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be84eb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgba.named_steps['preprocessor'].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3f0d82",
   "metadata": {},
   "source": [
    "#### Features importances globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9352220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des colonnes après preprocessing\n",
    "col = pd.DataFrame(best_model_RandomForest_CO2.named_steps['preprocessor'].get_feature_names_out())\n",
    "\n",
    "# Liste des coefficients de la régression Linéaire\n",
    "coef = []\n",
    "coef.append(best_model_RandomForest_CO2.named_steps['TransformedTargetRegressor'].regressor_.feature_importances_)\n",
    "\n",
    "# Dataframe des poids des coefficients\n",
    "weights_RandomForest_CO2 = pd.DataFrame(coef, columns=col)\n",
    "weights_RandomForest_CO2 = abs(weights_RandomForest_CO2).T.sort_values(by = 0, ascending = False).reset_index()\n",
    "weights_RandomForest_CO2.rename(columns={'index': 'features', 0: 'coef'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae3aeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed0e6a2b",
   "metadata": {},
   "source": [
    "#### Features importances locales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fcf99a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23d2ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7bf115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf223d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee44cfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05391ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99763ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f00d105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab18999",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lgb_smote1, df_lgb_smote1 = best_model(model_name = 'LightGBM',\n",
    "                                    model = LGBMClassifier(random_state = 42, verbose = -1),\n",
    "                                    xtrain = X_train,\n",
    "                                    numeric_features = feats,\n",
    "                                    numeric_transformer = StandardScaler(),\n",
    "                                    ytrain = y_train,\n",
    "                                    params = {\"classifier__ max_depth\": [1, 2, 3],\n",
    "                                              \"classifier__ n_estimators\": [1, 2, 3],},\n",
    "                                    scoring = make_scorer(score_metier),\n",
    "                                    xtest = X_test,\n",
    "                                    ytest = y_test,\n",
    "                                    oversampling_strategy = 0.1, undersampling_strategy = 0.5, balanced = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2919d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_smote1, df_lgb_smote1 = best_model(model_name = 'LightGBM',\n",
    "                                    model = LGBMClassifier(random_state = 42),\n",
    "                                    xtrain = X_train,\n",
    "                                    numeric_features = feats,\n",
    "                                    numeric_transformer = StandardScaler(),\n",
    "                                    ytrain = y_train,\n",
    "                                    params = {\"classifier__ max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                                              \"classifier__ num_leaves\": [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n",
    "                                              \"classifier__ learning_rate\": [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "                                              \"classifier__ n_estimators\": [10, 50, 100, 500, 1000, 5000],},\n",
    "                                    scoring = make_scorer(score_metier),\n",
    "                                    xtest = X_test,\n",
    "                                    ytest = y_test,\n",
    "                                    oversampling_strategy = 0.1, undersampling_strategy = 0.5, balanced = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b584a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb_smote1, df_lgb_smote1 = best_model(model_name = 'LightGBM',\n",
    "                                    model = LGBMClassifier(random_state = 42, verbose = -1),\n",
    "                                    xtrain = X_train,\n",
    "                                    numeric_features = feats_lgb,\n",
    "                                    numeric_transformer = StandardScaler(),\n",
    "                                    ytrain = y_train,\n",
    "                                    params = {\"classifier__ max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                                              \"classifier__ num_leaves\": [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n",
    "                                              \"classifier__ learning_rate\": [0.0001, 0.001, 0.01, 0.1, 1.0],},\n",
    "                                    scoring = make_scorer(score_metier),\n",
    "                                    xtest = X_test,\n",
    "                                    ytest = y_test,\n",
    "                                    oversampling_strategy = 0.1, undersampling_strategy = 0.5, balanced = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9258ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"classifier__ num_iterations\": [10, 50, 100, 500, 1000, 5000],\n",
    "                                              \"classifier__ max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                                              \"classifier__ num_leaves\": [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n",
    "                                              \"classifier__ learning_rate\": [0.0001, 0.001, 0.01, 0.1, 1.0],},"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b09b6b",
   "metadata": {},
   "source": [
    "### Choix du meilleur modèle <a class=\"anchor\" id=\"eval\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3de738",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_smote1.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01c5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ecf81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f472b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc804d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068f701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPERIMENT_NAME = \"mlflow-default-risk\"\n",
    "#EXPERIMENT_ID = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "start_Dummy = time.time()\n",
    "model = DummyClassifier()\n",
    "\n",
    "# Sélection des hyperparamètres\n",
    "params = {'strategy' : ['most_frequent', 'prior', 'stratified', 'uniform'],}\n",
    "scoring = make_scorer(recall_score)\n",
    "\n",
    "best_model_Dummy, best_params_Dummy = optimize_and_train_model(pipeline_model = model,\n",
    "                                                                xtrain = X_train,\n",
    "                                                                ytrain = y_train,\n",
    "                                                                params = params,\n",
    "                                                                scoring = scoring)\n",
    "\n",
    "\n",
    "duration_Dummy = time.time() - start_Dummy\n",
    "    \n",
    "# Evaluation du modèle\n",
    "(recall, precision, accuracy, auc) = eval_metrics(best_model = best_model_Dummy,\n",
    "                                                    xtest = X_test,\n",
    "                                                    ytest = y_test)\n",
    "    \n",
    "print(f\"DummyClassifier Model with param strategy = {best_params_Dummy['strategy']}\")\n",
    "print()\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"AUC: {auc:.2f}\")\n",
    "print(f\"Train time: {duration_Dummy:.2f}\")\n",
    "\n",
    "# Start MLflow\n",
    "with mlflow.start_run() as run:\n",
    "#with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name=RUN_NAME) as run:\n",
    "    \n",
    "    # Run id\n",
    "    RUN_ID = run.info.run_id\n",
    "    \n",
    "    # log des paramètres et scores à chaque fois que le modèle est lancé\n",
    "    mlflow.log_param(\"strategy\", best_params_Dummy['strategy'])\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "    mlflow.log_metric(\"Tps_entrainement\", duration_Dummy)\n",
    "    \n",
    "    mlflow.sklearn.log_model(best_model_Dummy, \"dummyclassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3724da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855fd534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355d29c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5def1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a3593e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81f4dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad2182ca",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html\n",
    "\n",
    "https://datascience.stackexchange.com/questions/82780/how-to-implement-a-gridsearchcv-custom-scorer-that-is-dependent-on-a-training-fe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c353d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p>•\tFinir la partie exploration et la transformation et choix des features \n",
    "•\tCréer un environnement MLFlow permettant le tracking lors de l’entraînement des modèles, la visualisation et la comparaison via l’UI de MLFlow, ainsi que le stockage de manière centralisée des modèles.\n",
    "o\tIl faut au minimum le tracking des scores (scores métier, AUC), des hyperparamètres, des temps de traitement de fit et de prédiction, ainsi que le stockage de graphiques (ROC curve) et des modèles\n",
    "•\tUne fonction de tracking de logs \n",
    "\n",
    "Bonus (je te le mets pour que tu l'aies en tête mais je n'attends pas que tu le fasse tout de suite) :\n",
    "•\tAvant de construire les modèles, réfléchir à la fonction de coût métier : \n",
    "o\tLa problématique « métier » est de prendre en compte qu’un faux positifs (crédit non accordé à tort, donc manque à gagner de la marge pour la banque) n’a pas le même coût qu’un faux négatif (mauvais client à qui on accorde un prêt, donc perte sur le capital non remboursé). Un faux négatif est environ 10 fois plus coûteux qu’un faux positif. Les mesures techniques tels que le f1 score ne le prennent pas en compte.\n",
    "o\tLe score “métier” consiste à calculer une fonction de coût métier de type 10*FN + FP \n",
    "o\tLes modèles et leur hyperparamètres seront optimisés via un GridSearchCV ou équivalent sur ce score, faire aussi l’accuracy ou l’AUC comme élément de comparaison (le garder en référence)\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc26ff85",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>Suppression des variables avec 30% ou plus de NaN</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2286712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b5407b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3d0a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fcc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_kb_X2_15 = pipeline.transform(X_train[categ_feat])\n",
    "X_test_kb_X2_15 = pipeline.transform(X_test[categ_feat])\n",
    "\n",
    "# Liste des 15 variables catégorielles conservées lors du SelectKBest\n",
    "feats_kb_X2_15 = pipeline.get_feature_names_out().tolist()\n",
    "\n",
    "# Score des 15 features\n",
    "score_kb_X2_15 = sorted(fs.scores_, reverse=True)[0:15]\n",
    "\n",
    "# Dataframe\n",
    "dic_Chi2 = {'Features': feats_kb_X2_15,\n",
    "            'Chi2_Score':score_kb_X2_15,}\n",
    "df_Chi2 = pd.DataFrame(data = dic_Chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a009a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.transform(X_train[categ_feat])\n",
    "#pipeline.transform(X_test[categ_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da178fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.title('SelectKBest = 15')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "sns.barplot(data = df_Chi2, x = 'Chi2_Score', y = 'Features', palette='Purples_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae94fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline + entrainement avec sélection des 15 features\n",
    "preprocessor = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categ_feat)])\n",
    "fs = SelectKBest(score_func = chi2, k = 15)\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('feat_select',fs)])\n",
    "\n",
    "pipeline.fit(X_train[categ_feat], y_train)\n",
    "\n",
    "#X_train_kb_X2_15 = pipeline.transform(X_train[categ_feat])\n",
    "#X_train_kb_X2_15 = pipeline.transform(X_test[categ_feat])\n",
    "\n",
    "y_pred = pipeline.predict(X_test[categ_feat])\n",
    "score_biz = score_metier(y_test, y_pred)\n",
    "print(f'Score metier: {score_biz}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b8ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e735ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio à mettre en catégories: enx: tx endettement >33% etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e984ab5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eaf0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline + entrainement\n",
    "preprocessor = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categ_feat)],\n",
    "                                 remainder='drop')\n",
    "transform = VarianceThreshold(0.05)\n",
    "fs_categ = SelectKBest(score_func = chi2, k = 'all')\n",
    "\n",
    "pipeline = Pipeline(steps=[('ohe', preprocessor),\n",
    "                           ('varthresh',transform),\n",
    "                           ('feat_select',fs_categ)])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d4637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c48351",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nous allons ici sélectionner nos features par **RFE** (élimination récursive des caractéristiques) qui est une méthode wrapper.\n",
    "Il existe 2 hyperparamètres:\n",
    "- le choix du **nombre de features** à sélectionner \n",
    "- le choix de l'**algorithme** à utiliser\n",
    "\n",
    "Ces deux hyperparamètres peuvent être explorés, bien que la performance de la méthode ne dépende pas fortement de ces hyperparamètres.\n",
    "\n",
    "Le RFE va rechercher un **sous ensemble optimal de features** en commençant par les prendre toutes puis en les supprimant au fur et à mesure jusqu'à ce qu'il en reste le nombre souhaité. Le RFE va classer les caractéristiques en fonction de leur importance, écarter les moins importantes puis réajuster le modèle.\n",
    "\n",
    "Nous allons utiliser un DecisionTreeClassifier pour choisir les caractéristiques et fixer le nombre de caractéristiques à 15. Nous allons évaluer le modèle à l'aide d'une validation croisée stratifiée k-fold répétée, avec cinq répétitions et 10 plis. Nous\n",
    "Nous indiquerons la moyenne et l'écart-type de la précision du modèle pour l'ensemble des répétitions et des plis.\n",
    "plis. L'exemple complet est présenté ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3baae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation du modèle sur les données de test\n",
    "    (score_biz, recall, precision, accuracy, auc, y_pred) = eval_metrics(\n",
    "        best_model = best_model,\n",
    "        xtest = xtest[numeric_features],\n",
    "        ytest = ytest)\n",
    "    \n",
    "\n",
    "    matrice_confusion(ytest, y_pred, model_name)\n",
    "    \n",
    "    # Récap\n",
    "    dic_df_recap = {'Modèle':[model_name],\n",
    "                    'Features':[numeric_features],\n",
    "                    'Best_Params':[best_params],\n",
    "                    'Score_metier':[score_biz],\n",
    "                    'Recall':[recall], \n",
    "                    'Precision':[precision], \n",
    "                    'Accuracy':[accuracy], \n",
    "                    'AUC':[auc], \n",
    "                    \"Train_Time\": [duration],}\n",
    "    df_recap = pd.DataFrame(data = dic_df_recap)\n",
    "    display(df_recap)\n",
    "    \n",
    "    return best_model, df_recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee14295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2855c348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673e508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_metier(ytest, y_pred):\n",
    "    # Matrice de confusion transformée en array avec affectation aux bonnes catégories\n",
    "    (vn, fp, fn, vp) = confusion_matrix(ytest, y_pred).ravel()\n",
    "    \n",
    "    # Rappel avec action fp => à minimiser\n",
    "    score_metier = 10*fn + 2*fp\n",
    "    \n",
    "    return score_metier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330fde57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(best_model, xtest, ytest, beta_value):\n",
    "    \n",
    "    y_pred = best_model.predict(xtest)\n",
    "    \n",
    "    score_biz = score_metier(ytest, y_pred)\n",
    "    betascore = fbeta_score(ytest, y_pred, beta = beta_value)\n",
    "    recall = recall_score(ytest, y_pred)\n",
    "    precision = precision_score(ytest, y_pred)\n",
    "    accuracy = accuracy_score(ytest, y_pred)\n",
    "    auc = roc_auc_score(ytest, y_pred)\n",
    "    \n",
    "    return score_biz, betascore, recall, precision, accuracy, auc, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc39118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrice_confusion(ytest, ypred, model_name):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    cm = confusion_matrix(ytest, ypred)\n",
    "    sns.heatmap(cm,\n",
    "                xticklabels=['Y=0 (Non défaillant)', 'Y=1 (Défaillant)'],\n",
    "                yticklabels=['Y=0 (Non défaillant)', 'Y=1 (Défaillant)'],\n",
    "                annot=True,\n",
    "                fmt='d', \n",
    "                linewidth=.5, \n",
    "                cmap = sns.cubehelix_palette(as_cmap=True), cbar=False)\n",
    "    plt.title(f'Matrice de confusion: {model_name}')\n",
    "    plt.ylabel('Réalité')\n",
    "    plt.xlabel('Prédiction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_model(model, numeric_features, numeric_transformer):\n",
    "\n",
    "    # Transformations à effectuer sur nos variables\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),])\n",
    "\n",
    "    # Définition de la pipeline du modèle: étapes de preprocessing + classifier\n",
    "    pipeline_model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)])\n",
    "    \n",
    "    return pipeline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_model_balanced(model, numeric_features, numeric_transformer,\n",
    "                            oversampling_strategy, undersampling_strategy):\n",
    "\n",
    "    # Sur échantillonnage de la classe minoritaire (10% de la classe majoritaire ~= 23000)\n",
    "    oversampler = SMOTE(sampling_strategy = oversampling_strategy, random_state = 42)\n",
    "\n",
    "    # Sous échantillonnage pour réduire la classe majoritaire (50% de plus que la classe minoritaire ~= 46000\n",
    "    undersampler = RandomUnderSampler(sampling_strategy = undersampling_strategy, random_state = 42)\n",
    "    \n",
    "    # Transformations à effectuer sur nos variables\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),])\n",
    "    \n",
    "    # Définition de la pipeline du modèle: étapes de preprocessing + classifier\n",
    "    pipeline_model_balanced = pipe(steps=[\n",
    "        ('over', oversampler),\n",
    "        ('under', undersampler),\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)])\n",
    "    \n",
    "    return pipeline_model_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b73f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_and_train_model(pipeline_model, xtrain, ytrain, params, scoring, cv):\n",
    "    \n",
    "    _ = pipeline_model.fit(xtrain, ytrain)\n",
    "\n",
    "\n",
    "    # Réglage automatique des meilleurs hyperparamètres avec GridSearchCV\n",
    "    #inner_cv = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "    model_grid_cv = GridSearchCV(pipeline_model, \n",
    "                                 param_grid = params, \n",
    "                                 cv = cv, \n",
    "                                 scoring = scoring,\n",
    "                                 refit=True)\n",
    "\n",
    "    model_grid_cv.fit(xtrain, ytrain)\n",
    "    \n",
    "    best_model = model_grid_cv.best_estimator_\n",
    "    best_params = model_grid_cv.best_params_\n",
    "\n",
    "    return best_model, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd515d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_and_train_model_RSCV(pipeline_model, xtrain, ytrain, params, scoring):\n",
    "    \n",
    "    _ = pipeline_model.fit(xtrain, ytrain)\n",
    "\n",
    "\n",
    "    # Réglage automatique des meilleurs hyperparamètres avec GridSearchCV\n",
    "    inner_cv = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "    model_grid_cv = RandomizedSearchCV(pipeline_model, \n",
    "                                       param_distributions = params, \n",
    "                                       cv = inner_cv, \n",
    "                                       scoring = scoring,\n",
    "                                       refit=True)\n",
    "\n",
    "    model_grid_cv.fit(xtrain, ytrain)\n",
    "    \n",
    "    best_model = model_grid_cv.best_estimator_\n",
    "    best_params = model_grid_cv.best_params_\n",
    "\n",
    "    return best_model, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae5609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model_name, best_model, best_params, xtest, ytest, categ_features):\n",
    "    # Evaluation du modèle sur les données de test\n",
    "    (score_biz, recall, precision, accuracy, auc, y_pred) = eval_metrics(best_model = best_model,\n",
    "                                                                         xtest = xtest,\n",
    "                                                                         ytest = ytest)\n",
    "    \n",
    "    matrice_confusion(ytest, y_pred, model_name)\n",
    "    \n",
    "    # Récap\n",
    "    dic_df_recap = {'Modèle':[model_name],\n",
    "                    'Variables':[categ_features],\n",
    "                    'Best_Params':[best_params],\n",
    "                    'Score_metier':[score_biz],\n",
    "                    'Recall':[recall], \n",
    "                    'Precision':[precision], \n",
    "                    'Accuracy':[accuracy], \n",
    "                    'AUC':[auc],}\n",
    "                    #\"Train_Time\": [duration],\n",
    "    df_recap = pd.DataFrame(data = dic_df_recap)\n",
    "    display(df_recap)\n",
    "    \n",
    "    return best_model, df_recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(model_name, model,\n",
    "               xtrain, numeric_features, numeric_transformer, \n",
    "               ytrain, params, scoring, xtest, ytest, \n",
    "               oversampling_strategy = 0.1, undersampling_strategy = 0.5, balanced = False, Randomized = False):\n",
    "    \n",
    "    if balanced == False:\n",
    "        start = time.time()\n",
    "        model = pipeline_model(model = model,\n",
    "                               numeric_features = numeric_features,\n",
    "                               numeric_transformer = numeric_transformer)\n",
    "\n",
    "        if RandomizedSearchCV == False:\n",
    "            # Optimisation via cross validation & GridSearch\n",
    "            best_model, best_params = optimize_and_train_model(pipeline_model = model,\n",
    "                                                               xtrain = xtrain[numeric_features],\n",
    "                                                               ytrain = ytrain,\n",
    "                                                               params = params,\n",
    "                                                               scoring = scoring)\n",
    "            \n",
    "        else:\n",
    "            # Optimisation via cross validation & RandomizedSearch\n",
    "            best_model, best_params = optimize_and_train_model_RSCV(pipeline_model = model,\n",
    "                                                                    xtrain = xtrain[numeric_features],\n",
    "                                                                    ytrain = ytrain,\n",
    "                                                                    params = params,\n",
    "                                                                    scoring = scoring)\n",
    "\n",
    "\n",
    "        duration = time.time() - start\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        start = time.time()\n",
    "        model = pipeline_model_balanced(model, numeric_features, numeric_transformer,\n",
    "                                        oversampling_strategy = oversampling_strategy, \n",
    "                                        undersampling_strategy = undersampling_strategy)\n",
    "\n",
    "        if RandomizedSearchCV == False:\n",
    "        # Optimisation via cross validation & GridSearch\n",
    "            best_model, best_params = optimize_and_train_model(pipeline_model = model,\n",
    "                                                               xtrain = xtrain[numeric_features],\n",
    "                                                               ytrain = ytrain,\n",
    "                                                               params = params,\n",
    "                                                               scoring = scoring)\n",
    "        \n",
    "        else:\n",
    "            best_model, best_params = optimize_and_train_model_RSCV(pipeline_model = model,\n",
    "                                                                    xtrain = xtrain[numeric_features],\n",
    "                                                                    ytrain = ytrain,\n",
    "                                                                    params = params,\n",
    "                                                                    scoring = scoring)    \n",
    "\n",
    "\n",
    "        duration = time.time() - start\n",
    "\n",
    "    \n",
    "    # Evaluation du modèle sur les données de test\n",
    "    (score_biz, recall, precision, accuracy, auc, y_pred) = eval_metrics(\n",
    "        best_model = best_model,\n",
    "        xtest = xtest[numeric_features],\n",
    "        ytest = ytest)\n",
    "    \n",
    "\n",
    "    matrice_confusion(ytest, y_pred, model_name)\n",
    "    \n",
    "    # Récap\n",
    "    dic_df_recap = {'Modèle':[model_name],\n",
    "                    'Features':[numeric_features],\n",
    "                    'Best_Params':[best_params],\n",
    "                    'Score_metier':[score_biz],\n",
    "                    'Recall':[recall], \n",
    "                    'Precision':[precision], \n",
    "                    'Accuracy':[accuracy], \n",
    "                    'AUC':[auc], \n",
    "                    \"Train_Time\": [duration],}\n",
    "    df_recap = pd.DataFrame(data = dic_df_recap)\n",
    "    display(df_recap)\n",
    "    \n",
    "    return best_model, df_recap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet7",
   "language": "python",
   "name": "projet7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
